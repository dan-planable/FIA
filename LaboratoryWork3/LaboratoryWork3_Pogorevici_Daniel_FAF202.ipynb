{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the MiniMax algorithm with the following scoring function:\n",
    "Score = MaterialV alue + PositionalV alue\n",
    "For computing the MaterialValue, each piece is assigned a value (e.g., Pawn = 1, Knight = 3, Bishop = 3, Rook = 5, Queen = 9). Then you sum these values for your pieces and substract the value of the pieces of the oponent.\n",
    "For computing the PositionalValue, you should take into account the position of each pieces on the board (e.g the more squares a pawn has travelled, the higher their Posi- tionalValue etc.). You should then substract the opponent’s PositionalValue from your pieces’ PositionalValue. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly I calculate the material value of all the pieces of a given color on the chessboard. I iterate over the board, check the type and color of each piece, and accumulate. their values. After that, I calculate the positional value of all the pieces of a given color on the chessboard. I iterate over the board, check the type and color of each piece, and accumulate their positional values.\n",
    "Lastly, I calculate an overall evaluation score for a chessboard. I takes into account the material value, positional value, and piece activity value. The final score is a combination of these three factors and is used to determine the quality of the current board position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piece_value = {\n",
    "    'pawn': 1,\n",
    "    'knight': 3,\n",
    "    'bishop': 3,\n",
    "    'rook': 5,\n",
    "    'queen': 9,\n",
    "    'king': 0  \n",
    "}\n",
    "\n",
    "positional_value = {\n",
    "    'pawn': [[0, 0, 0, 0, 0, 0, 0, 0],\n",
    "             [1, 1, 1, 1, 1, 1, 1, 1],\n",
    "             [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "             [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "             [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "             [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "             [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "             [0, 0, 0, 0, 0, 0, 0, 0]],\n",
    "}\n",
    "def calculate_material_value(board, color):\n",
    "    material_value = 0\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            piece = board[i][j]\n",
    "            if isinstance(piece, ChessPiece) and piece.color == color:\n",
    "                material_value += piece_value[piece.piece_type]\n",
    "    return material_value\n",
    "\n",
    "def calculate_positional_value(board, color):\n",
    "    positional_value = 0\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            piece = board[i][j]\n",
    "            if isinstance(piece, ChessPiece) and piece.color == color:\n",
    "                positional_value += positional_value[piece.piece_type][i][j]\n",
    "    return positional_value\n",
    "\n",
    "def evaluate(board):\n",
    "    player_color = board.get_player_color()\n",
    "    opponent_color = board.get_opponent_color()\n",
    "\n",
    "    material_value = calculate_material_value(board, player_color) - calculate_material_value(board, opponent_color)\n",
    "    \n",
    "    positional_value = calculate_positional_value(board, player_color) - calculate_positional_value(board, opponent_color)\n",
    "    \n",
    "    piece_activity_value = calculate_piece_activity(board, player_color) - calculate_piece_activity(board, opponent_color)\n",
    "\n",
    "    final_score = material_value + positional_value + piece_activity_value\n",
    "\n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement Alpha-Beta Prunning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpha-beta pruning is applied in the minimax function, in both two main sections: one for the maximizing player and one for the minimizing player.\n",
    "It works by initially setting alpha to negative infinity. After that the algorithm explores potential moves, it updates the alpha value, representing the best result achievable for the maximizing player. If the beta value of the current branch becomes less than or equal to the alpha value, it means that the minimizing player has a better option elsewhere, so there's no need to explore further in this branch. The algorithm can break out of the loop, effectively pruning the rest of the branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_tree\n",
    "def minimax(board, depth, alpha, beta, max_player, save_move, data):\n",
    "\n",
    "    if depth == 0 or board.is_terminal():\n",
    "        data[1] = board.evaluate()\n",
    "        return data\n",
    "\n",
    "    if max_player:\n",
    "        max_eval = -math.inf\n",
    "        for i in range(8):\n",
    "            for j in range(8):\n",
    "                if isinstance(board[i][j], ChessPiece) and board[i][j].color != board.get_player_color():\n",
    "                    piece = board[i][j]\n",
    "                    moves = piece.filter_moves(piece.get_moves(board), board)\n",
    "                    for move in moves:\n",
    "                        board.make_move(piece, move[0], move[1], keep_history=True)\n",
    "                        evaluation = minimax(board, depth - 1, alpha, beta, False, False, data)[1]\n",
    "                        if save_move:\n",
    "                            if evaluation >= max_eval:\n",
    "                                if evaluation > data[1]:\n",
    "                                    data.clear()\n",
    "                                    data[1] = evaluation\n",
    "                                    data[0] = [piece, move, evaluation]\n",
    "                                elif evaluation == data[1]:\n",
    "                                    data[0].append([piece, move, evaluation])\n",
    "                        board.unmake_move(piece)\n",
    "                        max_eval = max(max_eval, evaluation)\n",
    "                        alpha = max(alpha, evaluation)\n",
    "                        if beta <= alpha:  # Alpha-beta pruning here\n",
    "                            break\n",
    "        return data\n",
    "    else:\n",
    "        min_eval = math.inf\n",
    "        for i in range(8):\n",
    "            for j in range(8):\n",
    "                if isinstance(board[i][j], ChessPiece) and board[i][j].color == board.get_player_color():\n",
    "                    piece = board[i][j]\n",
    "                    moves = piece.get_moves(board)\n",
    "                    for move in moves:\n",
    "                        board.make_move(piece, move[0], move[1], keep_history=True)\n",
    "                        evaluation = minimax(board, depth - 1, alpha, beta, True, False, data)[1]\n",
    "                        board.unmake_move(piece)\n",
    "                        min_eval = min(min_eval, evaluation)\n",
    "                        beta = min(beta, evaluation)\n",
    "                        if beta <= alpha:  # Alpha-beta pruning here\n",
    "                            break\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement an improved scoring (evaluation) method for MiniMax. For example, you could add values like KingSafetyValue, MobilityValue (nr of legal moves to each side), PawnStructureValue (can include penalties for isolated pawns, doubled pawns, and bonuses for passed pawns or a strong pawn chain), etc. You can also use Heuristic Evaluation Functions. Be creative!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task I made changes to the evaluate function and added a calculate piece activity function in order to improve it. So, basically now calculate_piece_activity function computes a value that represents the activity of a player's pieces, considering the number of legal moves available to each piece. After that, the score is computed by subtracting the material and positional values of the opponent from the values of the player, along with a piece activity value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(board):\n",
    "    player_color = board.get_player_color()\n",
    "    opponent_color = board.get_opponent_color()\n",
    "\n",
    "    material_value = calculate_material_value(board, player_color) - calculate_material_value(board, opponent_color)\n",
    "    \n",
    "    positional_value = calculate_positional_value(board, player_color) - calculate_positional_value(board, opponent_color)\n",
    "    \n",
    "    piece_activity_value = calculate_piece_activity(board, player_color) - calculate_piece_activity(board, opponent_color)\n",
    "\n",
    "    final_score = material_value + positional_value + piece_activity_value\n",
    "\n",
    "    return final_score\n",
    "\n",
    "def calculate_piece_activity(board, color):\n",
    "    piece_activity_value = 0\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            piece = board[i][j]\n",
    "            if isinstance(piece, ChessPiece) and piece.color == color:\n",
    "                moves = piece.filter_moves(piece.get_moves(board), board)\n",
    "                piece_activity_value += len(moves)\n",
    "    return piece_activity_value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
